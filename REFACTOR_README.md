# Sportsbook Minimal - Master-Worker Architecture

## üìã Arsitektur

Sistem ini menggunakan arsitektur **Master-Worker** yang scalable untuk scraping odds dari berbagai sportsbook dan mendeteksi peluang arbitrase.

### Komponen Utama

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    FastAPI Backend                       ‚îÇ
‚îÇ         (WebSocket Server, Event Matcher,                ‚îÇ
‚îÇ              Arbitrage Calculator)                       ‚îÇ
‚îÇ                    Port: 8000                            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚îÇ WebSocket
             ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ        ‚îÇ        ‚îÇ        ‚îÇ        ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ...
‚îÇWorker ‚îÇ ‚îÇWorker‚îÇ ‚îÇWorker‚îÇ ‚îÇWorker‚îÇ
‚îÇ  SBO  ‚îÇ ‚îÇ IBC  ‚îÇ ‚îÇ CMD  ‚îÇ ‚îÇ PIN  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
(Docker)  (Docker) (Docker) (Docker)
```

### Backend (FastAPI)
- **WebSocket Server**: Mengelola koneksi dengan workers
- **Event Matcher**: Mencocokkan pertandingan dari berbagai sportsbook
- **Arbitrage Calculator**: Menghitung peluang arbitrase
- **Port**: 8000

### Workers (Docker Containers)
- **Generic Worker**: Satu Docker image untuk semua sportsbook
- **Site-Specific Modules**: Modul scraping per sportsbook (SBO, IBC, CMD, dll)
- **Playwright Automation**: Scraping menggunakan browser automation
- **WebSocket Client**: Mengirim odds ke backend

## üìÅ Struktur Folder

```
/sportsbook-minimal
‚îú‚îÄ‚îÄ /backend                    # FastAPI Backend
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt
‚îÇ   ‚îú‚îÄ‚îÄ main.py                 # FastAPI app & WebSocket server
‚îÇ   ‚îú‚îÄ‚îÄ matcher.py              # Event matching logic
‚îÇ   ‚îî‚îÄ‚îÄ websocket_manager.py    # WebSocket connection manager
‚îÇ
‚îú‚îÄ‚îÄ /worker                     # Generic Worker
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile              # FIXED: User permissions untuk Playwright
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt
‚îÇ   ‚îú‚îÄ‚îÄ worker.py               # Main worker script
‚îÇ   ‚îî‚îÄ‚îÄ /sites                  # Site-specific scrapers
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îú‚îÄ‚îÄ sbo.py              # SBOBet scraper
‚îÇ       ‚îú‚îÄ‚îÄ ibc.py              # IBCBet scraper
‚îÇ       ‚îî‚îÄ‚îÄ cmd.py              # CMD368 scraper
‚îÇ
‚îú‚îÄ‚îÄ docker-compose.yml          # Orchestration
‚îî‚îÄ‚îÄ .env                        # Environment variables
```

## üöÄ Quick Start

### 1. Build & Start Services

```bash
# Build semua services
docker-compose build

# Start backend + redis + 3 workers (SBO, IBC, CMD)
docker-compose up -d

# Lihat logs
docker-compose logs -f

# Lihat logs specific service
docker-compose logs -f worker-sbo
docker-compose logs -f backend
```

### 2. Check Status

```bash
# Check health backend
curl http://localhost:8000/health

# Check connected workers
curl http://localhost:8000/workers

# Check latest odds
curl http://localhost:8000/odds
```

### 3. Add More Workers

Untuk menambahkan worker baru, edit `docker-compose.yml`:

```yaml
# Example: Add Pinnacle worker
worker-pinnacle:
  build:
    context: ./worker
    dockerfile: Dockerfile
  container_name: sportsbook-worker-pinnacle
  restart: unless-stopped
  environment:
    - SITE=pinnacle
    - BACKEND_WS_URL=ws://backend:8000/ws
    - SCRAPE_INTERVAL=30
    - PYTHONUNBUFFERED=1
  depends_on:
    backend:
      condition: service_healthy
  networks:
    - sportsbook-network
```

Kemudian buat file scraper `worker/sites/pinnacle.py`:

```python
"""
Pinnacle Scraper Module
"""
import logging
from typing import Dict, Any, List
from playwright.sync_api import Page

logger = logging.getLogger(__name__)

class PinnacleScraper:
    def __init__(self):
        self.url = "https://www.pinnacle.com"
        logger.info("PinnacleScraper initialized")
    
    def scrape_odds(self, page: Page) -> Dict[str, Any]:
        # Implement scraping logic
        pass
```

Dan update `worker/sites/__init__.py`:

```python
from .sbo import SBOScraper
from .ibc import IBCScraper
from .cmd import CMDScraper
from .pinnacle import PinnacleScraper

__all__ = ['SBOScraper', 'IBCScraper', 'CMDScraper', 'PinnacleScraper']
```

## üîß Konfigurasi

### Environment Variables (.env)

```bash
# Backend
LOG_LEVEL=info
PYTHONUNBUFFERED=1

# Redis
REDIS_URL=redis://:redis_password_2024@redis:6379

# Worker
BACKEND_WS_URL=ws://backend:8000/ws
SCRAPE_INTERVAL=30

# Site Credentials (optional)
SBO_USERNAME=your_username
SBO_PASSWORD=your_password
```

### Worker Environment Variables

Setiap worker dikonfigurasi via environment variable `SITE`:

- `SITE=sbo` ‚Üí Load `sites/sbo.py` (SBOScraper)
- `SITE=ibc` ‚Üí Load `sites/ibc.py` (IBCScraper)
- `SITE=cmd` ‚Üí Load `sites/cmd.py` (CMDScraper)

## üêõ Troubleshooting

### Playwright Permission Error

**FIXED** ‚úÖ Dockerfile sudah diperbaiki dengan:

1. Create user `worker` SEBELUM install Playwright
2. Switch ke `USER worker` sebelum `playwright install chromium`
3. Browser terinstall di `/home/worker/.cache/ms-playwright` (bukan `/root`)

### Worker tidak connect ke Backend

```bash
# Check backend logs
docker-compose logs backend

# Check worker logs
docker-compose logs worker-sbo

# Restart services
docker-compose restart backend worker-sbo
```

### Memory Issues

Workers menggunakan Playwright + Chromium yang memory-intensive:

- Default limit: 1GB per worker
- Minimum: 512MB
- Edit `docker-compose.yml` untuk menyesuaikan

```yaml
deploy:
  resources:
    limits:
      memory: 2G  # Increase if needed
```

## üìä API Endpoints

### Backend (FastAPI)

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/` | GET | Root info |
| `/health` | GET | Health check |
| `/workers` | GET | List connected workers |
| `/odds` | GET | Latest odds from all workers |
| `/ws` | WebSocket | Worker connection endpoint |

## üîÑ WebSocket Protocol

### Worker ‚Üí Backend

#### 1. Registration
```json
{
  "type": "worker:register",
  "worker_id": "worker-sbo-12345",
  "site": "sbo",
  "timestamp": "2024-12-10T10:00:00"
}
```

#### 2. Odds Update
```json
{
  "type": "odds:update",
  "worker_id": "worker-sbo-12345",
  "site": "sbo",
  "timestamp": "2024-12-10T10:00:30",
  "data": {
    "matches": [
      {
        "home_team": "Manchester United",
        "away_team": "Chelsea",
        "odds": {
          "ft_hdp": {"home": 1.95, "away": 1.90, "handicap": -0.5},
          "ft_ou": {"over": 2.00, "under": 1.85, "line": 2.5}
        }
      }
    ]
  }
}
```

### Backend ‚Üí Workers

#### Arbitrage Opportunities
```json
{
  "type": "arbitrage:opportunities",
  "timestamp": "2024-12-10T10:00:35",
  "count": 2,
  "opportunities": [...]
}
```

## üöÄ Scaling

### Horizontal Scaling

Untuk scale 10+ workers:

1. **Edit docker-compose.yml** - Copy worker service definition
2. **Change environment variable** - Set unique `SITE` value
3. **Create scraper module** - Implement site-specific logic in `worker/sites/`

### Resource Planning

| Workers | Memory | CPU |
|---------|--------|-----|
| 3 workers | ~3GB | 2 cores |
| 10 workers | ~10GB | 4 cores |
| 20 workers | ~20GB | 8 cores |

## üìù Development

### Local Development (Backend)

```bash
cd backend
pip install -r requirements.txt
uvicorn main:app --reload --port 8000
```

### Local Development (Worker)

```bash
cd worker
pip install -r requirements.txt

# Set environment
export SITE=sbo
export BACKEND_WS_URL=ws://localhost:8000/ws

# Run worker
python worker.py
```

### Testing Scraper Module

```python
from playwright.sync_api import sync_playwright
from sites.sbo import SBOScraper

with sync_playwright() as p:
    browser = p.chromium.launch(headless=False)
    context = browser.new_context()
    page = context.new_page()
    
    scraper = SBOScraper()
    result = scraper.scrape_odds(page)
    
    print(result)
    browser.close()
```

## üîê Security Notes

1. Change Redis password di `.env` dan `docker-compose.yml`
2. Jangan commit credentials ke Git
3. Use secrets management untuk production
4. Restrict network access (firewall rules)

## üìö Next Steps

1. ‚úÖ Struktur folder refactored
2. ‚úÖ Dockerfile fixed (Playwright permissions)
3. ‚úÖ Docker Compose setup
4. ‚è≥ Implement actual scraping logic per site
5. ‚è≥ Add arbitrage calculation
6. ‚è≥ Add database untuk logging
7. ‚è≥ Add monitoring & alerts

## üìÑ License

MIT

---

**Note**: Scraper modules (`sites/*.py`) saat ini masih placeholder. Anda perlu mengimplementasikan logic scraping actual sesuai dengan struktur HTML masing-masing sportsbook.
